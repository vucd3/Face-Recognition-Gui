# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'AddFaceGui.ui'
#
# Created by: PyQt5 UI code generator 5.15.3
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
import cv2
import os
from imutils import paths
import face_recognition
import pickle
import numpy as np
import re

class AddFace(object):
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(942, 621)
        MainWindow.setStyleSheet("background-color: white;")
    
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")

        self.MainWindow = MainWindow 

        font = QtGui.QFont('Arial', 12, QtGui.QFont.Bold)

        self.box = QtWidgets.QGroupBox(self.centralwidget)
        self.box.setGeometry(QtCore.QRect(600, 20, 311, 161))
        self.box.setObjectName("box")  
        self.box.setFont(font)
    
        self.box_2 = QtWidgets.QGroupBox(self.centralwidget)
        self.box_2.setGeometry(QtCore.QRect(590, 220, 311, 281))
        self.box_2.setObjectName("box_2")  
        self.box_2.setFont(font)

        self.label = QtWidgets.QLabel(self.centralwidget)
        self.label.setGeometry(QtCore.QRect(220, 10, 150, 51))
        self.label.setObjectName("label")

        self.webcam = QtWidgets.QLabel(self.centralwidget)
        self.webcam.setGeometry(QtCore.QRect(30, 70, 451, 421))
        self.webcam.setText("")
        self.webcam.setObjectName("webcam")
       
        MainWindow.setCentralWidget(self.centralwidget)

        self.name = QtWidgets.QLineEdit(self.box)
        self.name.setGeometry(20, 50, 211, 31)
        self.name.setObjectName("name")

        self.ok = QtWidgets.QPushButton(self.box)
        self.ok.setGeometry(250, 50, 51, 31)
        self.ok.setObjectName("ok")
        self.ok.setStyleSheet("background-color : red")

        self.train = QtWidgets.QPushButton(self.box_2)
        self.train.setGeometry(140, 40, 161, 41)
        self.train.setObjectName("train")
        self.train.setStyleSheet("background-color : red")

        self.quit = QtWidgets.QPushButton(self.centralwidget)
        self.quit.setGeometry(800, 520, 131, 41)
        self.quit.setObjectName("quit")
        self.quit.setStyleSheet("background-color: red")

        self.status = QtWidgets.QLabel(self.box)
        self.status.setGeometry(30, 110, 231, 31)
        self.status.setObjectName("status")

        self.status1 = QtWidgets.QTextBrowser(self.box_2)
        self.status1.setGeometry(30, 90, 271, 171)
        self.status1.setObjectName("status1")

        self.msg = QtWidgets.QMessageBox(self.centralwidget)

        self.title = "<span style=\" font-size:22pt; font-weight:600; color:#ff0000;\" >"
        self.title += "WEBCAM"

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)
    
        self.capture=cv2.VideoCapture(0)
        self.timer=QtCore.QTimer()
        self.timer.start(5)
        self.timer.timeout.connect(self.update_frame)
        
        self.timer1 = QtCore.QTimer()

        self.timer2 = QtCore.QTimer()
        #Processing clicked
        self.ok.clicked.connect(self.saveImage)
        self.train.clicked.connect(self.training)
        self.quit.clicked.connect(self.quitGui)

        self.run = 0

        self.face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
        self.faces = None
        self.roi = None
        
        self.image_saved = []
        self.image_name = []
        self.image_saved_new = []
        self.image_name_new = []

        self.data = {}

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "ADD FACE"))
        self.label.setText(_translate("MainWindow", self.title))
        self.box.setTitle(_translate("MainWindow", "Enter Name"))
        self.box_2.setTitle(_translate("MainWindow", "Training"))
        self.ok.setText(_translate("MainWindow", "OK"))
        self.train.setText(_translate("MainWindow", "TRAINING"))
        self.status.setText(_translate("MainWindow", ""))
        self.status1.setText(_translate("MainWindow", ""))
        self.quit.setText(_translate("MainWindow", "QUIT"))

    def update_frame(self):
        _, self.image=self.capture.read()
        self.detect_face()
        self.displayImage(self.image)

    def displayImage(self,img):
        outImage=QtGui.QImage(img,img.shape[1],img.shape[0],img.strides[0],QtGui.QImage.Format_RGB888)

        outImage=outImage.rgbSwapped()
      
        self.webcam.setPixmap(QtGui.QPixmap.fromImage(outImage))
        self.webcam.setScaledContents(True)

    def detect_face(self):
        self.faces = self.face_cascade.detectMultiScale(self.image, 1.5, 5)

        for (x, y, w, h) in self.faces:
            cv2.rectangle(self.image, (x, y), (x+w, y+h), (0, 255, 0), 5)

    def inList(self, image, img_arr):
        check = 0
        for i in img_arr:
            if np.array_equal(i, image) == True:
                check += 1
                break
        if check == 1:
            return True
        else:
            return False
    
    def getImageFromFile(self):
        if os.path.getsize("images.pickle") > 0:
            with open("images.pickle", "rb") as e:
                data = pickle.load(e)
            self.image_saved = data["images"]
            self.image_name = data["names"]
            e.close()

    def getDataOld(self):
        with open("encodings.pickle", "rb") as f:
            self.data = pickle.load(f)
            f.close()
            
    def getIndex(self, imagePath):
        a = imagePath.split('/')[-1]
        b = int(a[:len(a)-4])
        return b

    def showMessage(self):
        self.status.setText("")
        self.timer1.stop()

    def showTraining(self):
        self.msg.setWindowTitle("Training")
        self.msg.setText("Finish Training!")
        self.msg.exec()

    def training(self):  
        imagePaths = list(paths.list_images("Dataset"))
        imagePaths.sort(key=lambda f: int(re.sub('\D', '', f)))

        if not os.path.exists("encodings.pickle"):
            f = open("encodings.pickle", "wb")
            f.close()

        if os.path.getsize("encodings.pickle") > 0:
            self.getDataOld()
            knownEncodings = self.data['encodings']
            knownNames = self.data['names']
        else:
            knownEncodings = []
            knownNames = []

        self.getImageFromFile()

        self.image_saved_new = self.image_saved
        self.image_name_new = self.image_name

        # loop over the image paths
        for imagePath in imagePaths:
            # extract the person name from the image path
            name = imagePath.split(os.path.sep)[-2]

            # load the input image and convert it from RGB (OpenCV ordering)
            # to dlib ordering (RGB)
            image = cv2.imread(imagePath)
            if self.inList(image, self.image_saved) == False:
                rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                self.status1.append("[INFO] Processing image of {} {}/{}".format(name, self.getIndex(imagePath), 
                    len(os.listdir("Dataset/"+name))))

                self.image_saved_new.append(image)
                self.image_name_new.append(name)
            else:
                continue
            # detect the (x, y)-coordinates of the bounding boxes
            # corresponding to each face in the input image
            boxes = face_recognition.face_locations(rgb, model='hog')

            # compute the facial embedding for the face
            encodings = face_recognition.face_encodings(rgb, boxes)

            # loop over the encodings
            for encoding in encodings:
                # add each encoding + name to our set of known names and
                # encodings
                knownEncodings.append(encoding)
                knownNames.append(name)

        #dump the pixel of image 
        data_1 = {"images": self.image_saved_new, "names": self.image_name_new}
        e = open("images.pickle", "wb")
        e.write(pickle.dumps(data_1))
        e.close()

        # dump the facial encodings + names to disk
        data_2 = {"encodings": knownEncodings, "names": knownNames}
        f = open("encodings.pickle", "wb")
        f.write(pickle.dumps(data_2))
        f.close()

        self.showTraining()

    def saveImage(self):
        if self.name.text() == "":
            self.msg.setWindowTitle("Message")
            self.msg.setText("Please enter your name!")
            self.msg.exec()
        else:
            if not os.path.exists('Dataset/'+self.name.text()):
                os.makedirs('Dataset/'+self.name.text())
                self.run = 0
                self.run += 1
            else:
                if self.run == 0:
                    self.run += 1
                while str(self.run) + '.jpg' in os.listdir('Dataset/'+self.name.text()):
                    if str(self.run) + '.jpg' not in os.listdir('Dataset/'+self.name.text()):
                        break
                    self.run += 1

            self.detect_face()
            if len(self.faces) > 0 :
                for (x, y, w, h) in self.faces:
                    self.roi = self.image[y:y+h, x:x+w]

                cv2.imwrite('Dataset/{}/{}.jpg' .format(self.name.text(), self.run), self.roi)

                self.status.setText("Saved Face Succesfully!")
            else:
                self.status.setText("Saved Face Failed!")
            
            self.timer1.start(1000)
            self.timer1.timeout.connect(self.showMessage)
                
            if not os.path.exists('images.pickle'):
                f = open('images.pickle', 'wb')
                f.close()

    def quitGui(self):
        self.timer.stop()
        self.capture.release()
        cv2.destroyAllWindows()
        self.MainWindow.close()

if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    AddFaceGui = QtWidgets.QMainWindow()
    AddFaceGui.setWindowTitle("Add Face")
    ui = AddFace()
    ui.setupUi(AddFaceGui)
    AddFaceGui.show()
    sys.exit(app.exec_())
